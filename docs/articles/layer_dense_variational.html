<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Uncertainty estimates with layer_dense_variational • tfprobability</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Uncertainty estimates with layer_dense_variational">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">tfprobability</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.8.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/dynamic_linear_models.html">Dynamic linear models</a>
    </li>
    <li>
      <a href="../articles/hamiltonian_monte_carlo.html">Multi-level modeling with Hamiltonian Monte Carlo</a>
    </li>
    <li>
      <a href="../articles/layer_dense_variational.html">Uncertainty estimates with layer_dense_variational</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/tfprobability">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Uncertainty estimates with layer_dense_variational</h1>
                        <h4 class="author">Sigrid Keydana</h4>
            
            <h4 class="date">2019-10-25</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/tfprobability/blob/master/vignettes/layer_dense_variational.Rmd"><code>vignettes/layer_dense_variational.Rmd</code></a></small>
      <div class="hidden name"><code>layer_dense_variational.Rmd</code></div>

    </div>

    
    
<p>With <code>tfprobability</code>, we can compute uncertainty estimates for <code>keras</code> layers. This vignette shows how to do this for dense layers.</p>
<p>Our example will have two types of uncertainty estimated:</p>
<ul>
<li>that due to variation in the data (irreducible; a.k.a. <em>aleatoric</em>)</li>
<li>that due to the fact that we don’t know the true model (theoretically, minimizable in the limit of infinite data, a.k.a. <em>epistemic</em>)</li>
</ul>
<p>To achieve the former, we have our model learn the spread in the data; to achieve the latter, we use a <em>variational</em> layer that learns a posterior over the weights. Internally, this layer works by minimizing the <em>evidence lower bound</em> (ELBO), thus striving to find an approximative posterior that does two things:</p>
<ol style="list-style-type: decimal">
<li>fit the actual data well (put differently: achieve high <em>log likelihood</em>), and</li>
<li>stay close to a <em>prior</em> (as measured by <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL divergence</a>).</li>
</ol>
<p>As users, we get to specify the form of the posterior as well as that of the prior. But first let’s generate some data.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tensorflow)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="co"># assume it's version 1.14, with eager not yet being the default</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3">tf<span class="op">$</span>compat<span class="op">$</span>v1<span class="op">$</span><span class="kw">enable_v2_behavior</span>()</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tfprobability)</a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(keras)</a>
<a class="sourceLine" id="cb1-7" data-line-number="7"></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(dplyr)</a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tidyr)</a>
<a class="sourceLine" id="cb1-10" data-line-number="10"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(ggplot2)</a>
<a class="sourceLine" id="cb1-11" data-line-number="11"></a>
<a class="sourceLine" id="cb1-12" data-line-number="12"><span class="co"># generate the data</span></a>
<a class="sourceLine" id="cb1-13" data-line-number="13">x_min &lt;-<span class="st"> </span><span class="dv">-40</span></a>
<a class="sourceLine" id="cb1-14" data-line-number="14">x_max &lt;-<span class="st"> </span><span class="dv">60</span></a>
<a class="sourceLine" id="cb1-15" data-line-number="15">n &lt;-<span class="st"> </span><span class="dv">150</span></a>
<a class="sourceLine" id="cb1-16" data-line-number="16">w0 &lt;-<span class="st"> </span><span class="fl">0.125</span></a>
<a class="sourceLine" id="cb1-17" data-line-number="17">b0 &lt;-<span class="st"> </span><span class="dv">5</span></a>
<a class="sourceLine" id="cb1-18" data-line-number="18"></a>
<a class="sourceLine" id="cb1-19" data-line-number="19">normalize &lt;-<span class="st"> </span><span class="cf">function</span>(x) (x <span class="op">-</span><span class="st"> </span>x_min) <span class="op">/</span><span class="st"> </span>(x_max <span class="op">-</span><span class="st"> </span>x_min)</a>
<a class="sourceLine" id="cb1-20" data-line-number="20"></a>
<a class="sourceLine" id="cb1-21" data-line-number="21"><span class="co"># training data; predictor </span></a>
<a class="sourceLine" id="cb1-22" data-line-number="22">x &lt;-<span class="st"> </span>x_min <span class="op">+</span><span class="st"> </span>(x_max <span class="op">-</span><span class="st"> </span>x_min) <span class="op">*</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(n) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a>
<a class="sourceLine" id="cb1-23" data-line-number="23"></a>
<a class="sourceLine" id="cb1-24" data-line-number="24"><span class="co"># training data; target</span></a>
<a class="sourceLine" id="cb1-25" data-line-number="25">eps &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span>(n) <span class="op">*</span><span class="st"> </span>(<span class="dv">3</span> <span class="op">*</span><span class="st"> </span>(<span class="fl">0.25</span> <span class="op">+</span><span class="st"> </span>(<span class="kw"><a href="https://rdrr.io/pkg/keras/man/normalize.html">normalize</a></span>(x)) <span class="op">^</span><span class="st"> </span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb1-26" data-line-number="26">y &lt;-<span class="st"> </span>(w0 <span class="op">*</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span>(x)) <span class="op">+</span><span class="st"> </span>b0) <span class="op">+</span><span class="st"> </span>eps</a>
<a class="sourceLine" id="cb1-27" data-line-number="27"></a>
<a class="sourceLine" id="cb1-28" data-line-number="28"><span class="co"># test data (predictor)</span></a>
<a class="sourceLine" id="cb1-29" data-line-number="29">x_test &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/seq.html">seq</a></span>(x_min, x_max, <span class="dt">length.out =</span> n) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>()</a></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y), <span class="kw"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(x, y)) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span>()</a></code></pre></div>
<div class="figure">
<img src="images/uncertainty_data.png" alt="Simulated data" width="500"><p class="caption">
Simulated data
</p>
</div>
<p>Here is a simple, <em>trainable</em> prior (in <em>empirical Bayesian</em> spirit: A normal distribution where the network may learn the mean (but not the scale). Alternatively, we could disallow learning from the data by setting <code>trainable</code> to <code>FALSE</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">prior_trainable &lt;-</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="st">  </span><span class="cf">function</span>(kernel_size,</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">           <span class="dt">bias_size =</span> <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb3-4" data-line-number="4">           <span class="dt">dtype =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">    n &lt;-<span class="st"> </span>kernel_size <span class="op">+</span><span class="st"> </span>bias_size</a>
<a class="sourceLine" id="cb3-6" data-line-number="6">    <span class="kw"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7"><span class="st">      </span><span class="kw"><a href="../reference/layer_variable.html">layer_variable</a></span>(n, <span class="dt">dtype =</span> dtype, <span class="dt">trainable =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb3-8" data-line-number="8"><span class="st">      </span><span class="kw"><a href="../reference/layer_distribution_lambda.html">layer_distribution_lambda</a></span>(<span class="cf">function</span>(t) {</a>
<a class="sourceLine" id="cb3-9" data-line-number="9">        <span class="kw"><a href="../reference/tfd_independent.html">tfd_independent</a></span>(<span class="kw"><a href="../reference/tfd_normal.html">tfd_normal</a></span>(<span class="dt">loc =</span> t, <span class="dt">scale =</span> <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb3-10" data-line-number="10">                        <span class="dt">reinterpreted_batch_ndims =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-11" data-line-number="11">      })</a>
<a class="sourceLine" id="cb3-12" data-line-number="12">  }</a></code></pre></div>
<p>The posterior then is a normal, too:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">posterior_mean_field &lt;-</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="st">  </span><span class="cf">function</span>(kernel_size,</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">           <span class="dt">bias_size =</span> <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">           <span class="dt">dtype =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb4-5" data-line-number="5">    n &lt;-<span class="st"> </span>kernel_size <span class="op">+</span><span class="st"> </span>bias_size</a>
<a class="sourceLine" id="cb4-6" data-line-number="6">    c &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/Log.html">log</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/Log.html">expm1</a></span>(<span class="dv">1</span>))</a>
<a class="sourceLine" id="cb4-7" data-line-number="7">    <span class="kw"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(</a>
<a class="sourceLine" id="cb4-8" data-line-number="8">      <span class="kw"><a href="../reference/layer_variable.html">layer_variable</a></span>(<span class="dt">shape =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>n, <span class="dt">dtype =</span> dtype),</a>
<a class="sourceLine" id="cb4-9" data-line-number="9">      <span class="kw"><a href="../reference/layer_distribution_lambda.html">layer_distribution_lambda</a></span>(</a>
<a class="sourceLine" id="cb4-10" data-line-number="10">        <span class="dt">make_distribution_fn =</span> <span class="cf">function</span>(t) {</a>
<a class="sourceLine" id="cb4-11" data-line-number="11">          <span class="kw"><a href="../reference/tfd_independent.html">tfd_independent</a></span>(<span class="kw"><a href="../reference/tfd_normal.html">tfd_normal</a></span>(</a>
<a class="sourceLine" id="cb4-12" data-line-number="12">            <span class="dt">loc =</span> t[<span class="dv">1</span><span class="op">:</span>n],</a>
<a class="sourceLine" id="cb4-13" data-line-number="13">            <span class="dt">scale =</span> <span class="fl">1e-5</span> <span class="op">+</span><span class="st"> </span>tf<span class="op">$</span>nn<span class="op">$</span><span class="kw">softplus</span>(c <span class="op">+</span><span class="st"> </span>t[(n <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">:</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>n)])</a>
<a class="sourceLine" id="cb4-14" data-line-number="14">            ), <span class="dt">reinterpreted_batch_ndims =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb4-15" data-line-number="15">        }</a>
<a class="sourceLine" id="cb4-16" data-line-number="16">      )</a>
<a class="sourceLine" id="cb4-17" data-line-number="17">    ))</a>
<a class="sourceLine" id="cb4-18" data-line-number="18">  }</a></code></pre></div>
<p>Now for the main model. The variational-dense layer is defined to have two units, one for the distribution of means and distribution of scales each. <code>layer_distribution_lambda</code> then takes their respective outputs as the mean and scale of the posterior distribution.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">model &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/pkg/keras/man/keras_model_sequential.html">keras_model_sequential</a></span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="st">  </span><span class="kw"><a href="../reference/layer_dense_variational.html">layer_dense_variational</a></span>(</a>
<a class="sourceLine" id="cb5-3" data-line-number="3">    <span class="dt">units =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">    <span class="dt">make_posterior_fn =</span> posterior_mean_field,</a>
<a class="sourceLine" id="cb5-5" data-line-number="5">    <span class="dt">make_prior_fn =</span> prior_trainable,</a>
<a class="sourceLine" id="cb5-6" data-line-number="6">    <span class="co"># scale by the size of the dataset</span></a>
<a class="sourceLine" id="cb5-7" data-line-number="7">    <span class="dt">kl_weight =</span> <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>n</a>
<a class="sourceLine" id="cb5-8" data-line-number="8">  ) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb5-9" data-line-number="9"><span class="st">  </span><span class="kw"><a href="../reference/layer_distribution_lambda.html">layer_distribution_lambda</a></span>(<span class="cf">function</span>(x)</a>
<a class="sourceLine" id="cb5-10" data-line-number="10">    <span class="kw"><a href="../reference/tfd_normal.html">tfd_normal</a></span>(<span class="dt">loc =</span> x[, <span class="dv">1</span>, <span class="dt">drop =</span> <span class="ot">FALSE</span>],</a>
<a class="sourceLine" id="cb5-11" data-line-number="11">               <span class="dt">scale =</span> <span class="fl">1e-3</span> <span class="op">+</span><span class="st"> </span>tf<span class="op">$</span>math<span class="op">$</span><span class="kw">softplus</span>(<span class="fl">0.01</span> <span class="op">*</span><span class="st"> </span>x[, <span class="dv">2</span>, <span class="dt">drop =</span> <span class="ot">FALSE</span>])</a>
<a class="sourceLine" id="cb5-12" data-line-number="12">               )</a>
<a class="sourceLine" id="cb5-13" data-line-number="13">    )</a></code></pre></div>
<p>The model is then simply trained to minimize the negative log likelihood, and fitted like a normal <code>keras</code> network.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">negloglik &lt;-<span class="st"> </span><span class="cf">function</span>(y, model) <span class="op">-</span><span class="st"> </span>(model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/tfd_log_prob.html">tfd_log_prob</a></span>(y))</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/pkg/keras/man/reexports.html">compile</a></span>(<span class="dt">optimizer =</span> <span class="kw"><a href="https://rdrr.io/pkg/keras/man/optimizer_adam.html">optimizer_adam</a></span>(<span class="dt">lr =</span> <span class="fl">0.01</span>), <span class="dt">loss =</span> negloglik)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/pkg/keras/man/reexports.html">fit</a></span>(x, y, <span class="dt">epochs =</span> <span class="dv">1000</span>)</a></code></pre></div>
<p>Because of the uncertainty in the weights, this model does not predict one line, but an ensemble of lines. Each of these lines has its own opinion about the spread in the data. Here is a way we could display this – each colored line is the mean of a distribution, surrounded by a confidence band indicating +/- two standard deviations.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="co"># each time we ask the model to predict, we get a different line</span></a>
<a class="sourceLine" id="cb7-2" data-line-number="2">yhats &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="cf">function</span>(x) <span class="kw">model</span>(tf<span class="op">$</span><span class="kw">constant</span>(x_test)))</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">means &lt;-</a>
<a class="sourceLine" id="cb7-4" data-line-number="4"><span class="st">  </span>purrr<span class="op">::</span><span class="kw"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span>(yhats, purrr<span class="op">::</span><span class="kw"><a href="https://purrr.tidyverse.org/reference/compose.html">compose</a></span>(as.matrix, tfd_mean)) <span class="op">%&gt;%</span><span class="st"> </span>abind<span class="op">::</span><span class="kw"><a href="https://rdrr.io/pkg/abind/man/abind.html">abind</a></span>()</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">sds &lt;-</a>
<a class="sourceLine" id="cb7-6" data-line-number="6"><span class="st">  </span>purrr<span class="op">::</span><span class="kw"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span>(yhats, purrr<span class="op">::</span><span class="kw"><a href="https://purrr.tidyverse.org/reference/compose.html">compose</a></span>(as.matrix, tfd_stddev)) <span class="op">%&gt;%</span><span class="st"> </span>abind<span class="op">::</span><span class="kw"><a href="https://rdrr.io/pkg/abind/man/abind.html">abind</a></span>()</a>
<a class="sourceLine" id="cb7-7" data-line-number="7"></a>
<a class="sourceLine" id="cb7-8" data-line-number="8">means_gathered &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(x_test, means)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb7-9" data-line-number="9"><span class="st">  </span><span class="kw"><a href="https://tidyr.tidyverse.org/reference/gather.html">gather</a></span>(<span class="dt">key =</span> run, <span class="dt">value =</span> mean_val,<span class="op">-</span>X1)</a>
<a class="sourceLine" id="cb7-10" data-line-number="10">sds_gathered &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(x_test, sds)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb7-11" data-line-number="11"><span class="st">  </span><span class="kw"><a href="https://tidyr.tidyverse.org/reference/gather.html">gather</a></span>(<span class="dt">key =</span> run, <span class="dt">value =</span> sd_val,<span class="op">-</span>X1)</a>
<a class="sourceLine" id="cb7-12" data-line-number="12"></a>
<a class="sourceLine" id="cb7-13" data-line-number="13">lines &lt;-</a>
<a class="sourceLine" id="cb7-14" data-line-number="14"><span class="st">  </span>means_gathered <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="https://dplyr.tidyverse.org/reference/join.html">inner_join</a></span>(sds_gathered, <span class="dt">by =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"X1"</span>, <span class="st">"run"</span>))</a>
<a class="sourceLine" id="cb7-15" data-line-number="15">mean &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(means, <span class="dv">1</span>, mean)</a>
<a class="sourceLine" id="cb7-16" data-line-number="16"></a>
<a class="sourceLine" id="cb7-17" data-line-number="17"><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">mean =</span> <span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(mean)), <span class="kw"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(x, y)) <span class="op">+</span></a>
<a class="sourceLine" id="cb7-18" data-line-number="18"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb7-19" data-line-number="19"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span>(<span class="dt">legend.position =</span> <span class="st">"none"</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb7-20" data-line-number="20"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span>(<span class="kw"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="dt">x =</span> x_test, <span class="dt">y =</span> mean), <span class="dt">color =</span> <span class="st">"violet"</span>, <span class="dt">size =</span> <span class="fl">1.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb7-21" data-line-number="21"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span>(</a>
<a class="sourceLine" id="cb7-22" data-line-number="22">    <span class="dt">data =</span> lines,</a>
<a class="sourceLine" id="cb7-23" data-line-number="23">    <span class="kw"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="dt">x =</span> X1, <span class="dt">y =</span> mean_val, <span class="dt">color =</span> run),</a>
<a class="sourceLine" id="cb7-24" data-line-number="24">    <span class="dt">alpha =</span> <span class="fl">0.6</span>,</a>
<a class="sourceLine" id="cb7-25" data-line-number="25">    <span class="dt">size =</span> <span class="fl">0.5</span></a>
<a class="sourceLine" id="cb7-26" data-line-number="26">  ) <span class="op">+</span></a>
<a class="sourceLine" id="cb7-27" data-line-number="27"><span class="st">  </span><span class="kw"><a href="https://ggplot2.tidyverse.org/reference/geom_ribbon.html">geom_ribbon</a></span>(</a>
<a class="sourceLine" id="cb7-28" data-line-number="28">    <span class="dt">data =</span> lines,</a>
<a class="sourceLine" id="cb7-29" data-line-number="29">    <span class="kw"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(</a>
<a class="sourceLine" id="cb7-30" data-line-number="30">      <span class="dt">x =</span> X1,</a>
<a class="sourceLine" id="cb7-31" data-line-number="31">      <span class="dt">ymin =</span> mean_val <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_val,</a>
<a class="sourceLine" id="cb7-32" data-line-number="32">      <span class="dt">ymax =</span> mean_val <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sd_val,</a>
<a class="sourceLine" id="cb7-33" data-line-number="33">      <span class="dt">group =</span> run</a>
<a class="sourceLine" id="cb7-34" data-line-number="34">    ),</a>
<a class="sourceLine" id="cb7-35" data-line-number="35">    <span class="dt">alpha =</span> <span class="fl">0.05</span>,</a>
<a class="sourceLine" id="cb7-36" data-line-number="36">    <span class="dt">fill =</span> <span class="st">"grey"</span>,</a>
<a class="sourceLine" id="cb7-37" data-line-number="37">    <span class="dt">inherit.aes =</span> <span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb7-38" data-line-number="38">  )</a></code></pre></div>
<div class="figure">
<img src="images/uncertainty.png" alt="Displaying both epistemic and aleatoric uncertainty on the simulated dataset." width="500"><p class="caption">
Displaying both epistemic and aleatoric uncertainty on the simulated dataset.
</p>
</div>
<p>Summing up, using <code>layer_dense_variational</code> we are able to construct a posterior predictive distribution from an ensemble of models, where each single model by itself learns the spread in the data. For some more background narrative on this topic, see <a href="https://blogs.rstudio.com/tensorflow/posts/2019-06-05-uncertainty-estimates-tfprobability/">Adding uncertainty estimates to Keras models with tfprobability</a>.</p>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Sigrid Keydana.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
