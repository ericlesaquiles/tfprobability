<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Multi-level modeling with Hamiltonian Monte Carlo • tfprobability</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/flatly/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Multi-level modeling with Hamiltonian Monte Carlo">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">tfprobability</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.9.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/dynamic_linear_models.html">Dynamic linear models</a>
    </li>
    <li>
      <a href="../articles/hamiltonian_monte_carlo.html">Multi-level modeling with Hamiltonian Monte Carlo</a>
    </li>
    <li>
      <a href="../articles/layer_dense_variational.html">Uncertainty estimates with layer_dense_variational</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/tfprobability">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Multi-level modeling with Hamiltonian Monte Carlo</h1>
                        <h4 class="author">Sigrid Keydana</h4>
            
            <h4 class="date">2020-01-27</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/tfprobability/blob/master/vignettes/hamiltonian_monte_carlo.Rmd"><code>vignettes/hamiltonian_monte_carlo.Rmd</code></a></small>
      <div class="hidden name"><code>hamiltonian_monte_carlo.Rmd</code></div>

    </div>

    
    
<p>Hierarchical models of any complexity may be specified using <code><a href="../reference/tfd_joint_distribution_sequential.html">tfd_joint_distribution_sequential()</a></code>. As hinted at by that function’s name, it builds a representation of a joint distribution where every component may optionally depend on components declared before it.</p>
<p>The model is then fitted to data using some form of Monte Carlo algorithm – Hamiltonian Monte Carlo (HMC), in most cases. Supplementing Monte Carlo methods is an implementation of Variational Inference (VI), but we don’t cover VI in this document.</p>
<p>We illustrate the process by example, using the <em>reedfrogs</em> dataset from Richard McElreath’s <code>rethinking</code> package. Each row in the dataset describes one tadpole tank, with its initial count of inhabitants (<code>density</code>) and number of survivors (<code>surv</code>).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="co"># assume it's version 1.14, with eager not yet being the default</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tensorflow)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">tf<span class="op">$</span><span class="kw">enable_v2_behavior</span>()</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tfprobability)</a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(rethinking)</a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(zeallot)</a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(purrr)</a>
<a class="sourceLine" id="cb1-9" data-line-number="9"></a>
<a class="sourceLine" id="cb1-10" data-line-number="10"><span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="st">"reedfrogs"</span>)</a>
<a class="sourceLine" id="cb1-11" data-line-number="11">d &lt;-<span class="st"> </span>reedfrogs</a>
<a class="sourceLine" id="cb1-12" data-line-number="12"><span class="kw"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(d)</a></code></pre></div>
<pre><code>'data.frame':   48 obs. of  5 variables:
 $ density : int  10 10 10 10 10 10 10 10 10 10 ...
 $ pred    : Factor w/ 2 levels "no","pred": 1 1 1 1 1 1 1 1 2 2 ...
 $ size    : Factor w/ 2 levels "big","small": 1 1 1 1 2 2 2 2 1 1 ...
 $ surv    : int  9 10 7 10 9 9 10 9 4 9 ...
 $ propsurv: num  0.9 1 0.7 1 0.9 0.9 1 0.9 0.4 0.9 ...</code></pre>
<p>We port to <code>tfprobability</code> the partially-pooled model presented in McElreath’s book. With partial pooling, each tank gets its own probability of survival.</p>
<p>In the model specification, we list the global priors first; then comes the intermediate layer yielding the per-tank priors; finally we have the likelihood which in this case is a binomial:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">n_tadpole_tanks &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(d)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2">n_surviving &lt;-<span class="st"> </span>d<span class="op">$</span>surv</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">n_start &lt;-<span class="st"> </span>d<span class="op">$</span>density</a>
<a class="sourceLine" id="cb3-4" data-line-number="4"></a>
<a class="sourceLine" id="cb3-5" data-line-number="5">model &lt;-<span class="st"> </span><span class="kw"><a href="../reference/tfd_joint_distribution_sequential.html">tfd_joint_distribution_sequential</a></span>(</a>
<a class="sourceLine" id="cb3-6" data-line-number="6">  <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(</a>
<a class="sourceLine" id="cb3-7" data-line-number="7">    <span class="co"># a_bar, the prior for the mean of the normal distribution of per-tank logits</span></a>
<a class="sourceLine" id="cb3-8" data-line-number="8">    <span class="kw"><a href="../reference/tfd_normal.html">tfd_normal</a></span>(<span class="dt">loc =</span> <span class="dv">0</span>, <span class="dt">scale =</span> <span class="fl">1.5</span>),</a>
<a class="sourceLine" id="cb3-9" data-line-number="9">    <span class="co"># sigma, the prior for the variance of the normal distribution of per-tank logits</span></a>
<a class="sourceLine" id="cb3-10" data-line-number="10">    <span class="kw"><a href="../reference/tfd_exponential.html">tfd_exponential</a></span>(<span class="dt">rate =</span> <span class="dv">1</span>),</a>
<a class="sourceLine" id="cb3-11" data-line-number="11">    <span class="co"># normal distribution of per-tank logits</span></a>
<a class="sourceLine" id="cb3-12" data-line-number="12">    <span class="co"># parameters sigma and a_bar refer to the outputs of the above two distributions</span></a>
<a class="sourceLine" id="cb3-13" data-line-number="13">    <span class="cf">function</span>(sigma, a_bar) </a>
<a class="sourceLine" id="cb3-14" data-line-number="14">      <span class="kw"><a href="../reference/tfd_sample_distribution.html">tfd_sample_distribution</a></span>(</a>
<a class="sourceLine" id="cb3-15" data-line-number="15">        <span class="kw"><a href="../reference/tfd_normal.html">tfd_normal</a></span>(<span class="dt">loc =</span> a_bar, <span class="dt">scale =</span> sigma),</a>
<a class="sourceLine" id="cb3-16" data-line-number="16">        <span class="dt">sample_shape =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(n_tadpole_tanks)</a>
<a class="sourceLine" id="cb3-17" data-line-number="17">      ), </a>
<a class="sourceLine" id="cb3-18" data-line-number="18">    <span class="co"># binomial distribution of survival counts</span></a>
<a class="sourceLine" id="cb3-19" data-line-number="19">    <span class="co"># parameter l refers to the output of the normal distribution immediately above</span></a>
<a class="sourceLine" id="cb3-20" data-line-number="20">    <span class="cf">function</span>(l)</a>
<a class="sourceLine" id="cb3-21" data-line-number="21">      <span class="kw"><a href="../reference/tfd_independent.html">tfd_independent</a></span>(</a>
<a class="sourceLine" id="cb3-22" data-line-number="22">        <span class="kw"><a href="../reference/tfd_binomial.html">tfd_binomial</a></span>(<span class="dt">total_count =</span> n_start, <span class="dt">logits =</span> l),</a>
<a class="sourceLine" id="cb3-23" data-line-number="23">        <span class="dt">reinterpreted_batch_ndims =</span> <span class="dv">1</span></a>
<a class="sourceLine" id="cb3-24" data-line-number="24">      )</a>
<a class="sourceLine" id="cb3-25" data-line-number="25">  )</a>
<a class="sourceLine" id="cb3-26" data-line-number="26">)</a></code></pre></div>
<p>Our model technically being a <em>distribution</em>, we can verify it conforms to our expectations by <em>sampling</em> from it:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">s &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/tfd_sample.html">tfd_sample</a></span>(<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">s </a></code></pre></div>
<pre><code>[[1]]
tf.Tensor([2.1276963  0.26374984], shape=(2,), dtype=float32)

[[2]]
tf.Tensor([1.0527238 2.0026767], shape=(2,), dtype=float32)

[[3]]
tf.Tensor(
[[ 5.3084397e-01  4.1868687e-03  6.5364146e-01  2.2994227e+00
   ...
   2.0958326e+00  8.9087760e-01  1.6273866e+00  2.7854009e+00]
 [-5.5288523e-01  1.0414324e+00 -1.3420627e-01  2.5128570e+00
  ...
  -6.6325682e-01  3.0505228e+00  8.1649482e-01  1.0340663e+00]], shape=(2, 48), dtype=float32)

[[4]]
tf.Tensor(
[[ 7.  6.  7. 10. 10.  8. 10.  9.  7. 10.  9. 10. 10.  7.  9. 10. 22. 25.
  17. 22. 17. 19. 21. 22. 19. 19. 19. 25. 23. 25. 23. 15. 32. 33. 32. 34.
  35. 34. 28. 33. 33. 32. 26. 31. 33. 30. 31. 33.]
 [ 2.  8.  4. 10.  6.  1.  8.  3.  7.  9.  1.  0.  5. 10.  4.  5.  2. 21.
   1. 14.  4. 14.  9.  6. 12.  0. 20. 19.  1. 15. 15.  7. 30.  7. 12.  4.
  23.  3. 16. 34. 35.  5. 14. 10. 20. 32. 19. 24.]], shape=(2, 48), dtype=float32)</code></pre>
<p>Another useful correctness check is that it yields a scalar log likelihood:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/tfd_log_prob.html">tfd_log_prob</a></span>(s)</a></code></pre></div>
<pre><code>tf.Tensor([-149.4476  -193.44107], shape=(2,), dtype=float32)</code></pre>
<p>`</p>
<p>Besides the model, we need to specify the loss, which here is just the joint log likelihood of the parameters and the target variable:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">logprob &lt;-<span class="st"> </span><span class="cf">function</span>(a, s, l)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">  model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/tfd_log_prob.html">tfd_log_prob</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(a, s, l, n_surviving))</a></code></pre></div>
<p>Now we can set up HMC sampling, making use of <code>mcmc_simple_step_size_adaptation</code> for dynamic step size evolution based on a desired acceptance probability.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="co"># number of steps after burnin</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">n_steps &lt;-<span class="st"> </span><span class="dv">500</span></a>
<a class="sourceLine" id="cb9-3" data-line-number="3"><span class="co"># number of chains</span></a>
<a class="sourceLine" id="cb9-4" data-line-number="4">n_chain &lt;-<span class="st"> </span><span class="dv">4</span></a>
<a class="sourceLine" id="cb9-5" data-line-number="5"><span class="co"># number of burnin steps</span></a>
<a class="sourceLine" id="cb9-6" data-line-number="6">n_burnin &lt;-<span class="st"> </span><span class="dv">500</span></a>
<a class="sourceLine" id="cb9-7" data-line-number="7"></a>
<a class="sourceLine" id="cb9-8" data-line-number="8">hmc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/mcmc_hamiltonian_monte_carlo.html">mcmc_hamiltonian_monte_carlo</a></span>(</a>
<a class="sourceLine" id="cb9-9" data-line-number="9">  <span class="dt">target_log_prob_fn =</span> logprob,</a>
<a class="sourceLine" id="cb9-10" data-line-number="10">  <span class="dt">num_leapfrog_steps =</span> <span class="dv">3</span>,</a>
<a class="sourceLine" id="cb9-11" data-line-number="11">  <span class="co"># one step size for each parameter</span></a>
<a class="sourceLine" id="cb9-12" data-line-number="12">  <span class="dt">step_size =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>),</a>
<a class="sourceLine" id="cb9-13" data-line-number="13">) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb9-14" data-line-number="14"><span class="st">  </span><span class="kw"><a href="../reference/mcmc_simple_step_size_adaptation.html">mcmc_simple_step_size_adaptation</a></span>(<span class="dt">target_accept_prob =</span> <span class="fl">0.8</span>,</a>
<a class="sourceLine" id="cb9-15" data-line-number="15">                                   <span class="dt">num_adaptation_steps =</span> n_burnin)</a></code></pre></div>
<p>The actual sampling should run on the TensorFlow graph for performance. So if we’re executing in eager mode, we wrap the call in <code>tf_function</code>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="co"># initial values to start the sampler</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(initial_a, initial_s, initial_logits, .) <span class="op">%&lt;-%</span><span class="st"> </span>(model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/tfd_sample.html">tfd_sample</a></span>(n_chain))</a>
<a class="sourceLine" id="cb10-3" data-line-number="3"></a>
<a class="sourceLine" id="cb10-4" data-line-number="4"><span class="co"># optionally retrieve metadata such as acceptance ratio and step size</span></a>
<a class="sourceLine" id="cb10-5" data-line-number="5">trace_fn &lt;-<span class="st"> </span><span class="cf">function</span>(state, pkr) {</a>
<a class="sourceLine" id="cb10-6" data-line-number="6">  <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(pkr<span class="op">$</span>inner_results<span class="op">$</span>is_accepted,</a>
<a class="sourceLine" id="cb10-7" data-line-number="7">       pkr<span class="op">$</span>inner_results<span class="op">$</span>accepted_results<span class="op">$</span>step_size)</a>
<a class="sourceLine" id="cb10-8" data-line-number="8">}</a>
<a class="sourceLine" id="cb10-9" data-line-number="9"></a>
<a class="sourceLine" id="cb10-10" data-line-number="10">run_mcmc &lt;-<span class="st"> </span><span class="cf">function</span>(kernel) {</a>
<a class="sourceLine" id="cb10-11" data-line-number="11">  kernel <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/mcmc_sample_chain.html">mcmc_sample_chain</a></span>(</a>
<a class="sourceLine" id="cb10-12" data-line-number="12">    <span class="dt">num_results =</span> n_steps,</a>
<a class="sourceLine" id="cb10-13" data-line-number="13">    <span class="dt">num_burnin_steps =</span> n_burnin,</a>
<a class="sourceLine" id="cb10-14" data-line-number="14">    <span class="dt">current_state =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(initial_a, tf<span class="op">$</span><span class="kw">ones_like</span>(initial_s), initial_logits),</a>
<a class="sourceLine" id="cb10-15" data-line-number="15">    <span class="dt">trace_fn =</span> trace_fn</a>
<a class="sourceLine" id="cb10-16" data-line-number="16">  )</a>
<a class="sourceLine" id="cb10-17" data-line-number="17">}</a>
<a class="sourceLine" id="cb10-18" data-line-number="18"></a>
<a class="sourceLine" id="cb10-19" data-line-number="19">run_mcmc &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html">tf_function</a></span>(run_mcmc)</a>
<a class="sourceLine" id="cb10-20" data-line-number="20">res &lt;-<span class="st"> </span><span class="kw">run_mcmc</span>(hmc)</a></code></pre></div>
<p>Now <code>res$all_states</code> contains the samples from the four chains, while <code>res$trace</code> has the diagnostic output.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">mcmc_trace &lt;-<span class="st"> </span>res<span class="op">$</span>all_states</a></code></pre></div>
<p>In our example, we have three levels of learned parameters (the two “hyperpriors” and the per-tank prior), so the samples come as a list of three. For each distribution, the first dimension reflects the number of samples per chain, the second, the number of chains and the third, the number of parameters in the chain.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">map</a></span>(mcmc_trace, <span class="op">~</span><span class="st"> </span><span class="kw"><a href="https://purrr.tidyverse.org/reference/compose.html">compose</a></span>(dim, as.array)(.x))</a></code></pre></div>
<pre><code>[[1]]
[1] 500   4

[[2]]
[1] 500   4

[[3]]
[1] 500   4  48</code></pre>
<p>We can obtain the <em>rhat</em> value, as well as the effective sample size, using <code>mcmc_potential_scale_reduction</code> and <code>mcmc_effective_sample_size</code>, respectively:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw"><a href="../reference/mcmc_potential_scale_reduction.html">mcmc_potential_scale_reduction</a></span>(mcmc_trace)</a>
<a class="sourceLine" id="cb14-2" data-line-number="2"><span class="kw"><a href="../reference/mcmc_effective_sample_size.html">mcmc_effective_sample_size</a></span>(mcmc_trace)</a></code></pre></div>
<p>These again are returned as lists of three.</p>
<p>Rounding up on diagnostic output, we may inspect individual acceptance in <code>res$trace[[1]]</code> and step sizes in <code>res$trace[[2]]</code>.</p>
<p>For ways to plot the samples and create summary output, as well as some background narrative, see <a href="https://blogs.rstudio.com/tensorflow/posts/2019-05-06-tadpoles-on-tensorflow/">Tadpoles on TensorFlow: Hierarchical partial pooling with tfprobability</a> and its follow-up, <a href="https://blogs.rstudio.com/tensorflow/posts/2019-05-24-varying-slopes/">Hierarchical partial pooling, continued: Varying slopes models with TensorFlow Probability</a> on the TensorFlow for R blog.</p>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Sigrid Keydana.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
